{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for processing the data that I have, aligning labels for decoding\n",
    "Should import with py-scipystack\n",
    "For working with Sherlock's interface, need to import modules. Need to have specific module loading for it to work otherwise go to the input.sh and run those commands in this notebook. \n",
    "(here is the sequence that works: py-scipystack math py-autograd py-pytorch cuda praat )\n",
    "\n",
    "What features do we want?\n",
    "\n",
    "We have:\n",
    "1. phonemes per time\n",
    "2. silence\n",
    "3. F0 pitch per time (individually on Praat)\n",
    "4. dB per time (individually audio on Praat with line separation)\n",
    "\n",
    "TODO: (see more planning doc for more scripts)\n",
    "1. Volume (db); this is described as \"intensity\" on praat\n",
    "2. pitch characteristics (spectrogram?) (can get pitch Hz from the github script on praat: https://github.com/lennes/pitch-distributions/blob/master/collectPitchSamplesFromCorpus.praat)\n",
    "   1. idea here: may be able to use strongest power frequencies or extract from Praat (corroborate from Praat)\n",
    "   2. corroborate with MFA phonemes that are vocal\n",
    "\n",
    "Decoder characteristics:\n",
    "1. silence vs sound\n",
    "2. speech envelope (volume)\n",
    "3. maybe discretize pitch first into a few categories\n",
    "   -for pitch, probably need to normalize? and do relative pitch from average or something\n",
    "\n",
    "Create jupyter instance\n",
    "check dependencies\n",
    "figure out how to export Praat alignments and textgrids\n",
    "parse those into bins\n",
    "align audios with the cues that we have\n",
    "align labels with cues that we have\n",
    "\n",
    "other question: do we need to align at all? can bypass and use bin time of 20ms to align. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task audio, mic audio\n",
    "\n",
    "Use 'trial_start_nsp_analog_time', 'trial_end_nsp_analog_time'\n",
    "To align with nap time\n",
    "\n",
    "Check with last trial end in ns5\n",
    "\n",
    "Audio at 30KHz\n",
    "\n",
    "Can play audio back from ns5\n",
    "\n",
    "20ms binsize\n",
    "\n",
    "maybe also get the neural PSTHs around word onset?\n",
    "\n",
    "#delay time start\n",
    "#check if there is a delay with the ns5 data (use blackrock documentation)\n",
    "#load ns5 data--> one isneural, another is analog, other is digital\n",
    "#this has audio stream. check to make sure audio stream is aligned with what we expect with the 20ms bin timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testin2g2\n"
     ]
    }
   ],
   "source": [
    "#assume that labels are ready in 20ms time intervals\n",
    "#assume we know alignment thru redis clock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "ts_filepath = '/home/groups/henderj/rzwang/exp_data/prosody/t12-02-20-2025/20250220_082208_(1).mat'\n",
    "# 5. Load redis MATLAB file with nsp timestamp information.\n",
    "mat_data = sio.loadmat(ts_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block_number', 'block_start_time', 'all_candidate_sentence_acoustic_scores', 'graph_name', 'confirmation_epoch_start_redis_time', 'trial_start_nsp_analog_time', 'trial_end_nsp_analog_time', 'delay_duration_ms', 'all_candidate_sentence_oldlm_scores', 'cue3_start_nsp_analog_time', 'decoder_signal', 'all_candidate_sentence_newlm_scores', 'binned_neural_spike_band_power', 'session_description', 'confirmation_epoch_start_nsp_analog_time', 'binned_neural_redis_clock', 'binned_neural_threshold_crossings', 'task_type', 'participant', 'trial_start_redis_time', 'corrected_with_candidate', 'microphone_nsp_time', 'correct_status', 'inter_trial_duration_ms', 'trial_end_nsp_neural_time', 'cue', 'all_candidate_sentences', 'block_description', 'ngram_decoder_partial_output', '__version__', 'word_count_mismatch', 'norm_channel_stds', 'trial_accuracy_confirmation', 'binned_neural_nsp_timestamp', 'cue3', 'cue2_start_nsp_neural_time', 'trial_end_redis_time', 'cue3_start_redis_time', 'cue2_start_redis_time', 'trial_paused_by_CNRA', 'cue3_start_nsp_neural_time', 'confirmation_epoch_start_nsp_neural_time', 'go_cue_nsp_neural_time', 'final_decoded_sentence', 'button_pressed', 'all_candidate_sentence_total_scores', 'decoder_logit_output', 'cue2', 'cue1', 'using_correct_electrode_mapping', 'microphone_data', 'go_cue_redis_time', '__header__', '__globals__', 'norm_redis_times', 'trial_start_nsp_neural_time', 'go_cue_nsp_analog_time', 'current_decoding_context_string', 'norm_channel_means', 'cue2_start_nsp_analog_time', 'session_name', 'ngram_decoder_final_output', 'decoder_output_redis_clock', 'trial_timed_out']\n"
     ]
    }
   ],
   "source": [
    "print(mat_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1740068451564 1740068451584 1740068451604 ... 1740068502438\n",
      "  1740068502458 1740068502478]]\n",
      "(1, 2547)\n",
      "[[1740068439]]\n",
      "(2547, 256)\n",
      "(2547, 256)\n",
      "[]\n",
      "[u\"scaled_100wpm_POD0000000240_S0000228.wav;AND IF IT'S MICHAEL;4;1.650000000000091;podcast;2.42;1.82;1.45                  \"\n",
      " u'scaled_100wpm_POD0000000320_S0000205.wav;I CAN PLAY THE MOVIE;5;1.5399999999999636;podcast;3.25;2.44;1.95                '\n",
      " u\"scaled_100wpm_POD0000000416_S0000055.wav;WHO ARE COGNIZANT OF WHAT'S HAPPENING;6;2.7299999999999613;podcast;2.2;1.65;1.32\"\n",
      " u'scaled_100wpm_AUD0000001043_S0000823.wav;NONE FOR ME;3;1.2300000000000182;audiobook;2.44;1.83;1.46                       '\n",
      " u'scaled_100wpm_POD0000000352_S0000314.wav;MONDAY BEGAN LIKE A NORMAL DAY;6;1.8199999999999363;podcast;3.3;2.47;1.98       ']\n",
      "[[1.72667492e+18 1.72667492e+18 1.72667492e+18 ... 1.72667497e+18\n",
      "  1.72667497e+18 1.72667497e+18]]\n",
      "[[1.72667492e+18 1.72667494e+18 1.72667495e+18 1.72667495e+18\n",
      "  1.72667496e+18]]\n",
      "[[1.74006846e+12 1.74006847e+12 1.74006848e+12 1.74006849e+12\n",
      "  1.74006850e+12]]\n",
      "[[1.74006845e+12 1.74006847e+12 1.74006847e+12 1.74006848e+12\n",
      "  1.74006849e+12]]\n",
      "[[1.74006847e+12 1.74006847e+12 1.74006848e+12 1.74006849e+12\n",
      "  1.74006850e+12]]\n"
     ]
    }
   ],
   "source": [
    "#mat_data probing. Let's go on redis clock, rather than nsp time (since bins are currently in redis time)\n",
    "#bins should be 20ms bins\n",
    "print(mat_data['binned_neural_redis_clock']) #starts at 1740068451564, ends 1740068502478. Probably the end of bins? or the start of bins\n",
    "#todo: check whether bin times are start or end boundaries\n",
    "print(mat_data['binned_neural_redis_clock'].shape) #1x2547 long\n",
    "print(mat_data['block_start_time']) #1740068439\n",
    "print(mat_data['binned_neural_spike_band_power'].shape) #array of floats, 2547x256 (time x array)\n",
    "print(mat_data['binned_neural_threshold_crossings'].shape) #binary array, 2547x256 (time x array)\n",
    "print(mat_data['task_type'])\n",
    "print(mat_data['cue']) #array of cue lines (audio file, corresponding transcript, number of words. can use this to match trials with labels/audio files, potentially)\n",
    "#side note: I also have block .txt files that have this information\n",
    "print(mat_data['binned_neural_nsp_timestamp'])\n",
    "print(mat_data['go_cue_nsp_neural_time'])\n",
    "print(mat_data['go_cue_redis_time']) #go cues for each trial, on the redis clock\n",
    "print(mat_data['trial_start_redis_time']) #trial start times on the redis clock\n",
    "print(mat_data['trial_end_redis_time']) #trial end times on the redis clock\n",
    "\n",
    "\n",
    "#I think it's the binned_neural_redis_clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "block_start = mat_data['block_start_time'][0][0]  # 1740068439\n",
    "\n",
    "bin_times = mat_data['binned_neural_redis_clock'][0]  # 1x2547 array\n",
    "\n",
    "# Bins appear to be 20ms (difference between consecutive times is 20)\n",
    "# Trial-specific timing\n",
    "\n",
    "trial_starts = mat_data['trial_start_redis_time'][0]\n",
    "trial_ends = mat_data['trial_end_redis_time'][0]\n",
    "go_cues = mat_data['go_cue_redis_time'][0]\n",
    "cues = mat_data['cue']  # Contains audio filename, transcript, word count, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_to_npy(mat_file_path, output_dir):\n",
    "    mat_data = sio.loadmat(mat_file_path)\n",
    "    np.save(f\"{output_dir}/spike_band_power.npy\", mat_data['binned_neural_spike_band_power'])\n",
    "    np.save(f\"{output_dir}/threshold_crossings.npy\",mat_data['binned_neural_threshold_crossings'])\n",
    "    np.save(f\"{output_dir}/bin_times.npy\", mat_data['binned_neural_redis_clock'][0])\n",
    "    np.save(f\"{output_dir}/go_times.npy\", mat_data['go_cue_redis_time'][0])\n",
    "    np.save(f\"{output_dir}/trial_starts.npy\", mat_data['trial_start_redis_time'][0])\n",
    "    np.save(f\"{output_dir}/trial_ends.npy\", mat_data['trial_start_redis_time'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
